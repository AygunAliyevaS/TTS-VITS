{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Google Colab Setup\n",
    "\n",
    "These cells help you set up Google Colab for efficient training:\n",
    "- Mount Google Drive to save checkpoints\n",
    "- Keep Colab from disconnecting\n",
    "- Upload project files as a ZIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directory for checkpoints\n",
    "import os\n",
    "checkpoint_dir = '/content/drive/MyDrive/VITS_Azerbaijani_Checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "print(f\"Checkpoints will be saved to: {checkpoint_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep Colab from disconnecting (click repeatedly)\n",
    "from IPython.display import display, Javascript\n",
    "import time\n",
    "\n",
    "def keep_alive():\n",
    "    display(Javascript('''\n",
    "        function ClickConnect(){\n",
    "            console.log(\"Clicking the connect button\");\n",
    "            document.querySelector(\"colab-connect-button\").click()\n",
    "        }\n",
    "        setInterval(ClickConnect, 60000)\n",
    "    '''))\n",
    "\n",
    "print(\"Keep-alive activated. Colab will click connect every 60 seconds.\")\n",
    "keep_alive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload project files as a ZIP\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "def upload_and_extract_project():\n",
    "    print(\"Please upload the project ZIP file...\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    for filename in uploaded.keys():\n",
    "        if filename.endswith('.zip'):\n",
    "            print(f\"Extracting {filename}...\")\n",
    "            # Extract to current directory\n",
    "            !unzip -o \"{filename}\"\n",
    "            print(f\"Extracted {filename} successfully!\")\n",
    "        else:\n",
    "            print(f\"Skipping {filename} - not a ZIP file\")\n",
    "    \n",
    "    # Check for main project files\n",
    "    if os.path.exists('train.py'):\n",
    "        print(\"✅ Project files extracted successfully!\")\n",
    "        !ls -la\n",
    "    else:\n",
    "        print(\"❌ Project files not found. Ensure your ZIP has the project files in its root.\")\n",
    "\n",
    "# Execute the function\n",
    "upload_and_extract_project()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a549917a",
   "metadata": {},
   "source": [
    "# VITS Azerbaijani Text-to-Speech Tutorial\n",
    "\n",
    "This unified notebook walks you through an **end-to-end** workflow for training and using a VITS model for Azerbaijani TTS, including *zero-shot voice cloning* and an interactive **Gradio** demo.\n",
    "\n",
    "**Sections**\n",
    "1. Google Colab Setup (Drive mount, upload project)\n",
    "2. Installation & Environment setup\n",
    "3. Configuration overview\n",
    "4. Dataset preparation & filelists\n",
    "5. Audio preprocessing & normalization\n",
    "6. Model training with checkpoint saving\n",
    "7. Inference examples (TTS & voice cloning)\n",
    "8. Web demo with Gradio\n",
    "\n",
    "> ⚠️ Designed for Google Colab (GPU) but works locally with minor tweaks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ee24c7",
   "metadata": {},
   "source": [
    "## 2. Installation & Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23beb2fb",
   "metadata": {
    "tags": [
     "colab"
    ]
   },
   "outputs": [],
   "source": [
    "# System packages (phonemizer backend)\n",
    "!apt-get update -y && apt-get install -y espeak ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8960c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages\n",
    "!pip install -q torch torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q numpy scipy librosa unidecode tensorboard phonemizer webdataset gradio tqdm pydub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f70ace0",
   "metadata": {},
   "source": [
    "## 3. Configuration overview\n",
    "\n",
    "The project ships with two JSON configs in `config/`:\n",
    "- **`base_vits.json`** – main training hyper-parameters  \n",
    "- **`hifigan.json`** – HiFiGAN vocoder settings (used internally by VITS)\n",
    "\n",
    "Feel free to tweak, e.g. `batch_size`, `learning_rate`, or enable multi-speaker training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pprint, pathlib\n",
    "cfg_path = pathlib.Path('config/base_vits.json')\n",
    "with cfg_path.open() as f:\n",
    "    hps = json.load(f)\n",
    "pprint.pp(hps['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8287d081",
   "metadata": {},
   "source": [
    "## 4. Dataset preparation & filelists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Upload dataset ZIP if needed\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "def upload_and_extract_dataset():\n",
    "    print(\"Please upload your dataset ZIP file...\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    for filename in uploaded.keys():\n",
    "        if filename.endswith('.zip'):\n",
    "            print(f\"Extracting {filename} to datasets/...\")\n",
    "            os.makedirs('datasets', exist_ok=True)\n",
    "            !unzip -o \"{filename}\" -d datasets/\n",
    "            print(f\"Dataset extracted successfully!\")\n",
    "            !ls -la datasets/\n",
    "        else:\n",
    "            print(f\"Skipping {filename} - not a ZIP file\")\n",
    "\n",
    "# Uncomment and run if you need to upload a dataset\n",
    "# upload_and_extract_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6556d1f",
   "metadata": {},
   "source": [
    "Each line in the filelists must follow:\n",
    "```text\n",
    "path/to/audio.wav|Azerbaijani transcript\n",
    "```\n",
    "Use the helper script below to auto-generate `train.txt` and `val.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Audio preprocessing & normalization\n",
    "\n",
    "It's important to normalize audio before training to ensure consistent volume levels and remove any DC offset. Let's add a preprocessing step for that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "def process_audio_file(file_path, target_sr=22050, target_level=-23.0, output_dir=None):\n",
    "    \"\"\"Normalize audio file to target level and resample to target sample rate.\"\"\"\n",
    "    try:\n",
    "        # Determine output path\n",
    "        if output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            filename = os.path.basename(file_path)\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "        else:\n",
    "            output_path = file_path\n",
    "            \n",
    "        # Load audio\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Resample if needed\n",
    "        if sr != target_sr:\n",
    "            y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "            sr = target_sr\n",
    "        \n",
    "        # Remove DC offset\n",
    "        y = y - np.mean(y)\n",
    "        \n",
    "        # Normalize audio level (RMS)\n",
    "        rms = np.sqrt(np.mean(y**2))\n",
    "        target_rms = 10**(target_level/20)\n",
    "        gain = target_rms / (rms + 1e-8)\n",
    "        y_normalized = y * gain\n",
    "        \n",
    "        # Apply slight compression to prevent clipping\n",
    "        max_val = np.max(np.abs(y_normalized))\n",
    "        if max_val > 0.99:\n",
    "            y_normalized = y_normalized / max_val * 0.99\n",
    "        \n",
    "        # Save the processed file\n",
    "        sf.write(output_path, y_normalized, sr)\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "def normalize_dataset(dataset_dir, output_dir=None):\n",
    "    \"\"\"Normalize all WAV files in a directory.\"\"\"\n",
    "    wav_files = glob.glob(os.path.join(dataset_dir, \"**\", \"*.wav\"), recursive=True)\n",
    "    print(f\"Found {len(wav_files)} WAV files to process\")\n",
    "    \n",
    "    if not wav_files:\n",
    "        print(\"No WAV files found!\")\n",
    "        return\n",
    "    \n",
    "    # Process files with progress bar\n",
    "    with multiprocessing.Pool(processes=os.cpu_count()) as pool:\n",
    "        args = [(f, 22050, -23.0, output_dir) for f in wav_files]\n",
    "        results = list(tqdm(pool.starmap(process_audio_file, args), total=len(args)))\n",
    "    \n",
    "    success_count = results.count(True)\n",
    "    print(f\"Successfully processed {success_count} of {len(wav_files)} files\")\n",
    "\n",
    "# Run normalization on your dataset\n",
    "# Uncomment and run when needed:\n",
    "# normalize_dataset('datasets', output_dir='datasets_normalized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python data/tools/prepare_filelist.py \\\n",
    "    --wavs datasets \\\n",
    "    --output data/filelists \\\n",
    "    --val-ratio 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1be57d",
   "metadata": {},
   "source": [
    "## 6. Model training with checkpoint saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Progress Monitor\n",
    "\n",
    "Run this cell in a separate tab to monitor training progress and ensure your drive is properly saving checkpoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "# Paths to monitor - always use local checkpoints directory\n",
    "checkpoint_dir = 'checkpoints'\n",
    "\n",
    "# Monitor function\n",
    "def monitor_training(interval=60):\n",
    "    try:\n",
    "        while True:\n",
    "            # Check for checkpoint files\n",
    "            checkpoint_files = glob.glob(f\"{checkpoint_dir}/*.pt\")\n",
    "            \n",
    "            # Print status\n",
    "            print(f\"\\n=== Training Status: {time.strftime('%Y-%m-%d %H:%M:%S')} ===\")\n",
    "            print(f\"Found {len(checkpoint_files)} checkpoint files in {checkpoint_dir}\")\n",
    "            \n",
    "            if checkpoint_files:\n",
    "                # Sort by modification time (newest first)\n",
    "                checkpoint_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n",
    "                \n",
    "                # Show most recent checkpoints\n",
    "                print(\"\\nMost recent checkpoints:\")\n",
    "                for i, ckpt in enumerate(checkpoint_files[:3]):\n",
    "                    mod_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(os.path.getmtime(ckpt)))\n",
    "                    size_mb = os.path.getsize(ckpt) / (1024 * 1024)\n",
    "                    print(f\"{i+1}. {os.path.basename(ckpt)} - {size_mb:.2f} MB - Last modified: {mod_time}\")\n",
    "            else:\n",
    "                print(\"No checkpoints found yet. Training may not have saved a checkpoint.\")\n",
    "                \n",
    "            # Wait for next check\n",
    "            print(f\"\\nNext check in {interval} seconds...\")\n",
    "            time.sleep(interval)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nMonitoring stopped\")\n",
    "\n",
    "# Run the monitor (uncomment to start)\n",
    "# monitor_training(interval=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b36fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up backup for important checkpoints if on Colab\n",
    "import os, sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    # Define paths\n",
    "    local_checkpoint_dir = 'checkpoints'\n",
    "    drive_backup_dir = '/content/drive/MyDrive/VITS_Azerbaijani_Checkpoints'\n",
    "    \n",
    "    # Make sure both directories exist\n",
    "    os.makedirs(local_checkpoint_dir, exist_ok=True)\n",
    "    os.makedirs(drive_backup_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Training will use local checkpoints folder. Best model will be backed up to Google Drive.\")\n",
    "    \n",
    "    # Create a script to back up important checkpoints\n",
    "    with open('backup_checkpoints.py', 'w') as f:\n",
    "        f.write(\"\"\"\n",
    "import os, shutil, time\n",
    "import glob\n",
    "\n",
    "def backup_important_checkpoints():\n",
    "    src_dir = 'checkpoints'\n",
    "    dst_dir = '/content/drive/MyDrive/VITS_Azerbaijani_Checkpoints'\n",
    "    \n",
    "    # Check if best model exists and back it up\n",
    "    best_model = os.path.join(src_dir, 'best.pt')\n",
    "    if os.path.exists(best_model):\n",
    "        shutil.copy2(best_model, os.path.join(dst_dir, 'best.pt'))\n",
    "        print(f\"Backed up best model to {dst_dir}\")\n",
    "    \n",
    "    # Also back up latest checkpoint\n",
    "    checkpoints = glob.glob(f\"{src_dir}/*.pt\")\n",
    "    if checkpoints:\n",
    "        latest = max(checkpoints, key=os.path.getmtime)\n",
    "        if not latest.endswith('best.pt'):\n",
    "            latest_name = os.path.basename(latest)\n",
    "            shutil.copy2(latest, os.path.join(dst_dir, latest_name))\n",
    "            print(f\"Backed up latest checkpoint {latest_name} to {dst_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        backup_important_checkpoints()\n",
    "        time.sleep(300)  # Check every 5 minutes\n",
    "\"\"\")\n",
    "    \n",
    "    # Start backup script in background\n",
    "    !nohup python backup_checkpoints.py > backup_log.txt 2>&1 &\n",
    "    print(\"Automatic checkpoint backup running in background\")\n",
    "\n",
    "# Run training with local checkpoint directory\n",
    "!python train.py \\\n",
    "  --config config/base_vits.json \\\n",
    "  --batch_size 16 \\\n",
    "  --epochs 1000 \\\n",
    "  --checkpoint_dir checkpoints \\\n",
    "  --log_dir logs \\\n",
    "  --save_every 10 \\\n",
    "  --keep_last 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7245d8d3",
   "metadata": {},
   "source": [
    "## 7. Inference examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83312b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, IPython.display as ipd\n",
    "from model.vits import VITSInference  # helper class provided in repo\n",
    "import glob\n",
    "import os, sys\n",
    "\n",
    "# Always use the local checkpoints directory\n",
    "checkpoint_dir = 'checkpoints'\n",
    "\n",
    "# Find the best or latest checkpoint\n",
    "checkpoint_files = glob.glob(f\"{checkpoint_dir}/*.pt\")\n",
    "if not checkpoint_files:\n",
    "    print(f\"No checkpoint files found in {checkpoint_dir}!\")\n",
    "    checkpoint_path = None\n",
    "else:\n",
    "    # Prefer best.pt if it exists, otherwise use latest\n",
    "    if os.path.exists(os.path.join(checkpoint_dir, 'best.pt')):\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, 'best.pt')\n",
    "    else:\n",
    "        # Get the most recent checkpoint\n",
    "        checkpoint_path = max(checkpoint_files, key=os.path.getmtime)\n",
    "    \n",
    "    print(f\"Using checkpoint: {os.path.basename(checkpoint_path)}\")\n",
    "\n",
    "    # Initialize the model\n",
    "    tts = VITSInference(\n",
    "        checkpoint=checkpoint_path,\n",
    "        config='config/base_vits.json')\n",
    "\n",
    "    # Basic synthesis\n",
    "    audio = tts.synthesize('Salam dünya! Bu VITS nümunəsidir.')\n",
    "    ipd.display(ipd.Audio(audio, rate=22050))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd81e1",
   "metadata": {},
   "source": [
    "### Voice cloning (zero-shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7eacf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a reference voice file\n",
    "reference_wav = None\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import files\n",
    "    print(\"Upload a reference voice file (.wav):\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if uploaded:\n",
    "        reference_wav = list(uploaded.keys())[0]\n",
    "        print(f\"Using uploaded file: {reference_wav}\")\n",
    "    else:\n",
    "        # Use example file\n",
    "        reference_wav = 'datasets/02.wav'\n",
    "        print(f\"Using default file: {reference_wav}\")\n",
    "else:\n",
    "    # Use example file\n",
    "    reference_wav = 'datasets/02.wav'\n",
    "\n",
    "# Try voice cloning if the model and reference file are available\n",
    "if 'tts' in locals() and reference_wav and os.path.exists(reference_wav):\n",
    "    cloned = tts.synthesize(\n",
    "        'Mənim səsimlə danışan süni zəka!',\n",
    "        speaker_ref=reference_wav)\n",
    "    ipd.display(ipd.Audio(cloned, rate=22050))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1516b732",
   "metadata": {},
   "source": [
    "## 8. Gradio demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on Colab, make sure to use a public URL\n",
    "if 'google.colab' in sys.modules:\n",
    "    !python app.py --share   # launches public URL\n",
    "else:\n",
    "    !python app.py   # launches on http://<your_ip>:7860"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
